import json
import os
import torch

from src.retrievers.text_retriever import TextRetriever
from src.retrievers.image_retriever import ImageRetriever
from src.retrievers.chart_retriever import ChartRetriever

from src.agents.seeker_agent import SeekerAgent
from src.agents.inspector_agent import InspectorAgent
from src.agents.synthesizer_agent import SynthesizerAgent

from src.models.gumbel_selector import GumbelModalSelector
from src.orchestrator import RAGOrchestrator
from src.utils.embedding_utils import QueryEmbedder, get_query_embedding


def main():
    print("ğŸš€ Initializing Multi-Agent RAG System")

    # 1) è®¾å¤‡ä¸æŸ¥è¯¢åµŒå…¥æ¨¡å‹
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\n[1] åˆå§‹åŒ–æŸ¥è¯¢åµŒå…¥å™¨... (device={device})")
    q_embedder = QueryEmbedder(model_name="BAAI/bge-m3", device=device)

    # 2) åŠ è½½æ ·ä¾‹
    print("\n[2] åŠ è½½æµ‹è¯•æ ·æœ¬...")
    dataset_path = "data/ViDoSeek/rag_dataset.json"
    with open(dataset_path, "r", encoding="utf-8") as f:
        examples = json.load(f)["examples"]

    test_num = 10

    for i in range(test_num):
        sample_idx = i
        sample = examples[sample_idx]
        query = sample["query"]

        # ç»Ÿä¸€çš„ Query Embedding
        query_embedding = get_query_embedding(q_embedder, query)

        # å¯é€‰ï¼šå¼ºåˆ¶æŸä¸€è·¯ï¼ˆ0=text, 1=image, 2=chartï¼‰ï¼›ä¸å¼ºåˆ¶ç”¨ None
        # force_modality = None

        if sample["meta_info"]["source_type"] == "text":
            force_modality = 0
        else:
            force_modality = 1

        # 3) æ£€ç´¢å™¨æ‡’åŠ è½½å·¥å‚ï¼ˆä¸æå‰å®ä¾‹åŒ–ï¼Œé¿å…é‡å¤åˆå§‹åŒ–ä¸é¢„ç¼–ç ï¼‰
        print("\n[3] åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆæŒ‰éœ€ï¼‰...")
        factories = {
            "text": lambda: TextRetriever(node_dir="data/ViDoSeek/bge_ingestion"),
            "image": lambda: ImageRetriever(
                node_dir="data/ViDoSeek/colqwen_ingestion",
                ocr_dir="data/ViDoSeek/bge_ingestion",
                text_encoder="BAAI/bge-m3",
                cache_dir=".cache/ocr_embeds",   # âœ… ä¿ç•™ç¼“å­˜ç›®å½•
                # âš ï¸ ä¸è¦å†ä¼  cache_fp16 äº†ï¼Œæ–°ç‰ˆä¸æ”¯æŒ
            ),
            "chart": lambda: ChartRetriever(node_dir="data/ViDoSeek/bge_ingestion"),
        }

        # ä¸æå‰å»ºï¼Œäº¤ç»™ orchestrator éœ€è¦æ—¶å†å»º
        text_retriever = None
        image_retriever = None
        chart_retriever = None

        # 4) ç»„è£…æ™ºèƒ½ä½“ä¸æ¨¡æ€é€‰æ‹©å™¨
        print("\n[4] ç»„è£…æ™ºèƒ½ä½“ä¸æ¨¡æ€é€‰æ‹©å™¨...")
        selector = GumbelModalSelector(
            input_dim=q_embedder.out_dim,  # 1024
            hidden_dim=0,
            num_choices=2,  # ç›®å‰åª text / image
            tau=1.0,
        )

        ckpt_path = "checkpoints/modal_selector_text_image.pt"
        if os.path.exists(ckpt_path):
            state = torch.load(ckpt_path, map_location="cpu")
            selector.load_state_dict(state, strict=False)
            selector.eval()
            print(f"âœ… Loaded selector weights from {ckpt_path}")
        else:
            print("â„¹ï¸ No selector checkpoint found, using randomly initialized selector.")

        seeker = SeekerAgent(
            text_retriever=text_retriever,
            image_retriever=image_retriever,
            chart_retriever=chart_retriever,
        )
        inspector = InspectorAgent()
        synthesizer = SynthesizerAgent(model_name="google/flan-t5-large")

        orchestrator = RAGOrchestrator(
            seeker=seeker,
            inspector=inspector,
            synthesizer=synthesizer,
            gumbel_selector=selector,
            use_modal_selector=True,
            # å…³é”®ï¼šæ°¸è¿œæŠŠä¸‰ç§ factory éƒ½ä¼ ä¸‹å»ï¼ŒçœŸæ­£ç”¨åˆ°å“ªä¸ªå†æ‡’åŠ è½½
            lazy_init_factories=factories,
        )

        print("\n" + "=" * 60)
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ŒæŸ¥è¯¢: '{query}'")
        print("=" * 60)

        # 5) è¿è¡Œç¼–æ’å™¨
        final_answer = orchestrator.run(query, query_embedding, force_modality=force_modality)

        # 6) æ‰“å°ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ‰ RAG æµç¨‹æ‰§è¡Œå®Œæ¯• ğŸ‰")
        print(f"\n[ç”¨æˆ·é—®é¢˜]: {query}")
        print("-" * 30)
        print(f"[æ¨¡å‹ç”Ÿæˆçš„æœ€ç»ˆç­”æ¡ˆ]:\n{final_answer}")
        print("-" * 30)
        print(f"[æ•°æ®ä¸­çš„å‚è€ƒç­”æ¡ˆ]:\n{sample.get('reference_answer', '(no reference)')}")
        print("=" * 60)


if __name__ == "__main__":
    main()