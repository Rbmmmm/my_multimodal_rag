# # File: run_all.py
# # ä½œç”¨: éå†æ•´ä¸ªæ•°æ®é›†ï¼Œè¿è¡ŒRAGæµç¨‹ï¼Œå¹¶å°†ç”Ÿæˆçš„ç»“æœä¿å­˜åˆ°æ–‡ä»¶ã€‚
# # ç‰¹ç‚¹:
# # 1. ä»£ç å®Œæ•´ï¼Œå¯ç›´æ¥è¿è¡Œã€‚
# # 2. å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿ç¨‹åºä¸å› å•ä¸ªæ ·æœ¬å¤±è´¥è€Œä¸­æ–­ã€‚
# # 3. è‡ªåŠ¨è®°å½•å¤„ç†å¤±è´¥çš„æ ·æœ¬åŠé”™è¯¯ä¿¡æ¯åˆ° _errors.jsonl æ–‡ä»¶ã€‚
# # 4. æ”¯æŒæ–­ç‚¹ç»­è·‘ï¼Œè‡ªåŠ¨è·³è¿‡å·²æˆåŠŸå¤„ç†çš„æ ·æœ¬ã€‚

# import os
# import torch
# import json
# from tqdm import tqdm
# from llama_index.core import Settings
# import traceback # ç”¨äºè·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

# # --- å¯¼å…¥æ‚¨çš„é¡¹ç›®ç»„ä»¶ ---
# from src.searcher.text_searcher import TextSearcher
# from src.searcher.image_searcher import ImageSearcher
# from src.searcher.table_searcher import TableSearcher
# from src.searcher.SearchEngine import SearchEngine
# from src.agent.seeker_agent import SeekerAgent
# from src.agent.inspector_agent import InspectorAgent
# from src.agent.synthesizer_agent import SynthesizerAgent
# from src.models.gumbel_selector import GumbelModalSelector
# from src.orchestrator import RAGOrchestrator
# from src.llms.llm import LLM
# from src.utils.embedding_utils import QueryEmbedder, get_query_embedding

# Settings.llm = None

# # --- é…ç½®åŒº ---
# CONFIG = {
#     "DATASET_PATH": "data/ViDoSeek/rag_dataset.json",
#     "OUTPUT_FILE": "generation_results/run_output.jsonl", # æ‰€æœ‰æˆåŠŸç»“æœå°†ä¿å­˜åœ¨è¿™é‡Œ
#     "TOP_K": 5
# }

# def main():
#     # ==========================================================================
#     # æ­¥éª¤ 1: åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿç»„ä»¶ (å®Œæ•´ç‰ˆ)
#     # ==========================================================================
#     print("="*30)
#     print("æ­¥éª¤ 1: åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿç»„ä»¶")
    
#     # --- 1a. è®¾ç½® API Key å’Œè®¾å¤‡ ---
#     print("\n[1a] è®¾ç½® vlm API Key...")
#     device = "cuda" if torch.cuda.is_available() else "cpu"
#     if "sk" in os.environ.get("DASHSCOPE_API_KEY", ""):
#         print("[1a] âœ… vlm API Key å·²æˆåŠŸè®¾ç½®.")
#     else:
#         print("[1a] âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ã€‚")

#     # --- 1b. åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å‹ ---
#     print("\n[1b] åˆå§‹åŒ– query åµŒå…¥æ¨¡å‹å’Œ vlm æ¨¡å‹...")
#     query_embedder = QueryEmbedder(model_name="BAAI/bge-m3", device=device)
#     vlm = LLM("qwen-vl-max")
#     print("[1b] âœ… åˆå§‹åŒ– query åµŒå…¥æ¨¡å‹å’Œ vlm æ¨¡å‹ å·²æˆåŠŸåˆå§‹åŒ–.")

#     # --- 1c. åˆ›å»ºæ£€ç´¢å™¨â€œå·¥å‚â€ (Retriever Factories) ---
#     print("\n[1c] åˆ›å»ºæ£€ç´¢å™¨å·¥å‚...")
#     retriever_factories = {
#         "text": lambda: TextSearcher(
#             dataset_name='ViDoSeek',
#             mode='hybrid',
#             node_dir_prefix='bge_ingestion' 
#         ),
#         "image": lambda: ImageSearcher(
#             dataset_name='ViDoSeek',
#             mode='vl_search',
#             vl_node_dir_prefix='colqwen_ingestion' 
#         ),
#         "table": lambda: TableSearcher(
#             dataset_name='ViDoSeek',
#             mode='vl_search',
#             vl_node_dir_prefix='colqwen_ingestion' 
#         )
#     }
#     print("[1c] âœ… æ£€ç´¢å™¨å·¥å‚å®Œæˆ...")

#     # --- 1d. åˆå§‹åŒ–æ”¯æŒæ‡’åŠ è½½çš„ SearchEngine ---
#     print("\n[1d] åˆå§‹åŒ–æ”¯æŒæ‡’åŠ è½½çš„ SearchEngine...")
#     search_engine = SearchEngine(retriever_factories=retriever_factories)
#     print("[1d] âœ… æ‡’åŠ è½½ SearchEngine å·²æˆåŠŸåˆå§‹åŒ–.")

#     # --- 1e. åˆå§‹åŒ– Gumbel æ¨¡æ€é€‰æ‹©å™¨ ---
#     print("\n[1e] åˆå§‹åŒ– Gumbel æ¨¡æ€é€‰æ‹©å™¨...")
#     gumbel_selector = GumbelModalSelector(
#         input_dim=query_embedder.out_dim,
#         num_choices=3 # 0=text, 1=image, 2=table
#     ).to(device).eval()

#     ckpt_path = "checkpoints/modal_selector_best.pt"
#     if os.path.exists(ckpt_path):
#         gumbel_selector.load_state_dict(torch.load(ckpt_path, map_location=device))
#         print(f"[1e] âœ… æˆåŠŸä» {ckpt_path} åŠ è½½ Gumbel Selector æƒé‡.")
#     else:
#         print("[1e] â„¹ï¸ æœªæ‰¾åˆ° Gumbel Selector æ£€æŸ¥ç‚¹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–.")

#     # --- 1f. åˆå§‹åŒ– seeker, inspector, synthesizer agents ---
#     print("\n[1f] åˆå§‹åŒ– agents...")
#     image_base_dir = "data/ViDoSeek/img" 
#     seeker_agent = SeekerAgent(vlm=vlm, image_base_dir=image_base_dir)
#     inspector_agent = InspectorAgent(vlm=vlm, image_base_dir=image_base_dir, reranker_model_name="BAAI/bge-reranker-large")
#     synthesizer_agent = SynthesizerAgent(vlm=vlm, image_base_dir=image_base_dir)
#     print("[1f] âœ… æ‰€æœ‰ agents å·²è¢«æˆåŠŸåˆå§‹åŒ–.")

#     # --- 1g. ç»„è£…æ€»æŒ‡æŒ¥ (Orchestrator) ---
#     print("\n[1g] åˆå§‹åŒ– orchestrator...")
#     orchestrator = RAGOrchestrator(
#         search_engine=search_engine,
#         seeker=seeker_agent,
#         inspector=inspector_agent,
#         synthesizer=synthesizer_agent,
#         gumbel_selector=gumbel_selector
#     )
#     print("[1g] âœ… Orchestrator å·²æˆåŠŸåˆå§‹åŒ–.")
    
#     print("\nâœ… æ­¥éª¤ä¸€ç»“æŸï¼šæ‰€æœ‰ç»„ä»¶å·²å°±ä½.")
#     print("="*30)

#     # ==========================================================================
#     # æ­¥éª¤ 2: æ‰¹é‡ç”Ÿæˆç»“æœ
#     # ==========================================================================
#     print("\næ­¥éª¤ 2: å¼€å§‹æ‰¹é‡ç”Ÿæˆç»“æœ")

#     with open(CONFIG["DATASET_PATH"], "r", encoding="utf-8") as f:
#         examples = json.load(f)["examples"]
    
#     # --- æ–­ç‚¹ç»­è·‘é€»è¾‘ ---
#     completed_uids = set()
#     output_dir = os.path.dirname(CONFIG["OUTPUT_FILE"])
#     if output_dir:
#         os.makedirs(output_dir, exist_ok=True)
        
#     if os.path.exists(CONFIG["OUTPUT_FILE"]):
#         print(f"â„¹ï¸  å‘ç°å·²å­˜åœ¨çš„ç»“æœæ–‡ä»¶ï¼Œå°†è¿›è¡Œæ–­ç‚¹ç»­è·‘...")
#         with open(CONFIG["OUTPUT_FILE"], "r", encoding="utf-8") as f:
#             for line in f:
#                 try:
#                     completed_uids.add(json.loads(line)["uid"])
#                 except (json.JSONDecodeError, KeyError):
#                     continue
#         print(f"âœ… å·²æˆåŠŸå¤„ç† {len(completed_uids)} ä¸ªæ ·æœ¬ï¼Œå°†è·³è¿‡å®ƒä»¬ã€‚")

#     # --- å¾ªç¯å¤„ç†æ‰€æœ‰æ ·æœ¬ ---
#     error_file_path = CONFIG["OUTPUT_FILE"].replace(".jsonl", "_errors.jsonl")
#     for sample in tqdm(examples, desc="æ­£åœ¨ç”Ÿæˆç»“æœ"):
#         uid = sample.get("uid")
#         query = sample.get("query")
        
#         if not query or (uid and uid in completed_uids):
#             continue

#         # --- å¯¹æ¯ä¸ªæ ·æœ¬çš„å¤„ç†éƒ½åŒ…è£¹åœ¨ try...except å—ä¸­ ---
#         try:
#             query_embedding = get_query_embedding(query_embedder, query)
            
#             # 1. ç‹¬ç«‹è·å–æ£€ç´¢ç»“æœ
#             modality_index = orchestrator._choose_modality(query_embedding)
#             modality_name = orchestrator.modality_map.get(modality_index, "unknown")
#             retrieved_nodes = search_engine.search(
#                 query=query, modality=modality_name, top_k=CONFIG["TOP_K"]
#             )
            
#             # 2. è¿è¡ŒOrchestratorè·å–ç­”æ¡ˆ (ä¼ å…¥å·²æ£€ç´¢çš„èŠ‚ç‚¹ä»¥é¿å…é‡å¤æ£€ç´¢)
#             # æç¤º: ä¸ºäº†è·å¾—æ€§èƒ½æå‡ï¼Œå»ºè®®ä¿®æ”¹æ‚¨çš„Orchestratorä»¥æ¥å—pre_retrieved_nodeså‚æ•°
#             final_answer = orchestrator.run(
#                 query=query,
#                 query_embedding=query_embedding,
#                 initial_top_k=CONFIG["TOP_K"],
#                 pre_retrieved_nodes=retrieved_nodes # å–æ¶ˆæ­¤è¡Œæ³¨é‡Šä»¥å¯ç”¨ä¼˜åŒ–
#             )

#             # --- å‡†å¤‡è¦ä¿å­˜çš„æ•°æ® ---
#             result_data = {
#                 "uid": uid,
#                 "query": query,
#                 "reference_answer": sample.get("reference_answer"),
#                 "meta_info": sample.get("meta_info"),
#                 "generated_answer": final_answer,
#                 "retrieved_nodes": [node.to_dict() for node in retrieved_nodes]
#             }

#             # --- å°†æˆåŠŸçš„ç»“æœå®æ—¶å†™å…¥æ–‡ä»¶ ---
#             with open(CONFIG["OUTPUT_FILE"], "a", encoding="utf-8") as f:
#                 f.write(json.dumps(result_data, ensure_ascii=False) + "\n")

#         except Exception as e:
#             # --- å¦‚æœå‘ç”Ÿå¼‚å¸¸ï¼Œè®°å½•é”™è¯¯å¹¶ç»§ç»­ ---
#             print(f"\nâŒ å¤„ç†æ ·æœ¬ {uid} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
#             error_details = {
#                 "uid": uid,
#                 "query": query,
#                 "error_message": str(e),
#                 "traceback": traceback.format_exc() # è®°å½•å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯
#             }
#             # å†™å…¥ç‹¬ç«‹çš„é”™è¯¯æ—¥å¿—æ–‡ä»¶
#             with open(error_file_path, "a", encoding="utf-8") as f:
#                 f.write(json.dumps(error_details, ensure_ascii=False) + "\n")
#             continue # ç»§ç»­ä¸‹ä¸€ä¸ªæ ·æœ¬
    
#     print("\nğŸ‰ æ‰€æœ‰æ ·æœ¬ç”Ÿæˆå®Œæ¯•ï¼")
#     print(f"âœ… æˆåŠŸç»“æœå·²ä¿å­˜è‡³: {CONFIG['OUTPUT_FILE']}")
#     if os.path.exists(error_file_path):
#         print(f"âš ï¸  éƒ¨åˆ†æ ·æœ¬å¤„ç†å¤±è´¥ï¼Œé”™è¯¯è¯¦æƒ…å·²è®°å½•åœ¨: {error_file_path}")

# if __name__ == '__main__':
#     main()

# File: run_all.py (æœ€ç»ˆç‰ˆ)
# ä½œç”¨: éå†æ•´ä¸ªæ•°æ®é›†ï¼Œè¿è¡ŒRAGæµç¨‹ï¼Œå¹¶å°†ç”Ÿæˆçš„ç»“æœä¿å­˜åˆ°æ–‡ä»¶ã€‚
# ç‰¹ç‚¹:
# 1. ä»£ç å®Œæ•´ï¼Œå¯ç›´æ¥è¿è¡Œã€‚
# 2. å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿ç¨‹åºä¸å› å•ä¸ªæ ·æœ¬å¤±è´¥è€Œä¸­æ–­ã€‚
# 3. è‡ªåŠ¨è®°å½•å¤„ç†å¤±è´¥çš„æ ·æœ¬åŠé”™è¯¯ä¿¡æ¯åˆ° _errors.jsonl æ–‡ä»¶ã€‚
# 4. æ”¯æŒæœ€ç¨³å¥çš„æ–­ç‚¹ç»­è·‘ï¼šè‡ªåŠ¨è·³è¿‡æ‰€æœ‰å·²å¤„ç†è¿‡çš„æ ·æœ¬ï¼ˆæ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼‰ã€‚

import os
import torch
import json
from tqdm import tqdm
from llama_index.core import Settings
import traceback # ç”¨äºè·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

# --- å¯¼å…¥æ‚¨çš„é¡¹ç›®ç»„ä»¶ ---
from src.searcher.text_searcher import TextSearcher
from src.searcher.image_searcher import ImageSearcher
from src.searcher.table_searcher import TableSearcher
from src.searcher.SearchEngine import SearchEngine
from src.agent.seeker_agent import SeekerAgent
from src.agent.inspector_agent import InspectorAgent
from src.agent.synthesizer_agent import SynthesizerAgent
from src.models.gumbel_selector import GumbelModalSelector
from src.orchestrator import RAGOrchestrator
from src.llms.llm import LLM
from src.utils.embedding_utils import QueryEmbedder, get_query_embedding

Settings.llm = None

# --- é…ç½®åŒº ---
CONFIG = {
    "DATASET_PATH": "data/ViDoSeek/rag_dataset.json",
    "OUTPUT_FILE": "generation_results/run_output.jsonl", # æ‰€æœ‰æˆåŠŸç»“æœå°†ä¿å­˜åœ¨è¿™é‡Œ
    "TOP_K": 5
}

def main():
    # ==========================================================================
    # æ­¥éª¤ 1: åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿç»„ä»¶ (å®Œæ•´ç‰ˆ)
    # ==========================================================================
    print("="*30)
    print("æ­¥éª¤ 1: åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿç»„ä»¶")
    
    # --- 1a. è®¾ç½® API Key å’Œè®¾å¤‡ ---
    print("\n[1a] è®¾ç½® vlm API Key...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if "sk" in os.environ.get("DASHSCOPE_API_KEY", ""):
        print("[1a] âœ… vlm API Key å·²æˆåŠŸè®¾ç½®.")
    else:
        print("[1a] âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ã€‚")

    # --- 1b. åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å‹ ---
    print("\n[1b] åˆå§‹åŒ– query åµŒå…¥æ¨¡å‹å’Œ vlm æ¨¡å‹...")
    query_embedder = QueryEmbedder(model_name="BAAI/bge-m3", device=device)
    vlm = LLM("qwen-vl-max")
    print("[1b] âœ… åˆå§‹åŒ– query åµŒå…¥æ¨¡å‹å’Œ vlm æ¨¡å‹ å·²æˆåŠŸåˆå§‹åŒ–.")

    # --- 1c. åˆ›å»ºæ£€ç´¢å™¨â€œå·¥å‚â€ (Retriever Factories) ---
    print("\n[1c] åˆ›å»ºæ£€ç´¢å™¨å·¥å‚...")
    retriever_factories = {
        "text": lambda: TextSearcher(
            dataset_name='ViDoSeek',
            mode='hybrid',
            node_dir_prefix='bge_ingestion' 
        ),
        "image": lambda: ImageSearcher(
            dataset_name='ViDoSeek',
            mode='vl_search',
            vl_node_dir_prefix='colqwen_ingestion' 
        ),
        "table": lambda: TableSearcher(
            dataset_name='ViDoSeek',
            mode='vl_search',
            vl_node_dir_prefix='colqwen_ingestion' 
        )
    }
    print("[1c] âœ… æ£€ç´¢å™¨å·¥å‚å®Œæˆ...")

    # --- 1d. åˆå§‹åŒ–æ”¯æŒæ‡’åŠ è½½çš„ SearchEngine ---
    print("\n[1d] åˆå§‹åŒ–æ”¯æŒæ‡’åŠ è½½çš„ SearchEngine...")
    search_engine = SearchEngine(retriever_factories=retriever_factories)
    print("[1d] âœ… æ‡’åŠ è½½ SearchEngine å·²æˆåŠŸåˆå§‹åŒ–.")

    # --- 1e. åˆå§‹åŒ– Gumbel æ¨¡æ€é€‰æ‹©å™¨ ---
    print("\n[1e] åˆå§‹åŒ– Gumbel æ¨¡æ€é€‰æ‹©å™¨...")
    gumbel_selector = GumbelModalSelector(
        input_dim=query_embedder.out_dim,
        num_choices=3 # 0=text, 1=image, 2=table
    ).to(device).eval()

    ckpt_path = "checkpoints/modal_selector_best.pt"
    if os.path.exists(ckpt_path):
        gumbel_selector.load_state_dict(torch.load(ckpt_path, map_location=device))
        print(f"[1e] âœ… æˆåŠŸä» {ckpt_path} åŠ è½½ Gumbel Selector æƒé‡.")
    else:
        print("[1e] â„¹ï¸ æœªæ‰¾åˆ° Gumbel Selector æ£€æŸ¥ç‚¹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–.")

    # --- 1f. åˆå§‹åŒ– seeker, inspector, synthesizer agents ---
    print("\n[1f] åˆå§‹åŒ– agents...")
    image_base_dir = "data/ViDoSeek/img" 
    seeker_agent = SeekerAgent(vlm=vlm, image_base_dir=image_base_dir)
    inspector_agent = InspectorAgent(vlm=vlm, image_base_dir=image_base_dir, reranker_model_name="BAAI/bge-reranker-large")
    synthesizer_agent = SynthesizerAgent(vlm=vlm, image_base_dir=image_base_dir)
    print("[1f] âœ… æ‰€æœ‰ agents å·²è¢«æˆåŠŸåˆå§‹åŒ–.")

    # --- 1g. ç»„è£…æ€»æŒ‡æŒ¥ (Orchestrator) ---
    print("\n[1g] åˆå§‹åŒ– orchestrator...")
    orchestrator = RAGOrchestrator(
        search_engine=search_engine,
        seeker=seeker_agent,
        inspector=inspector_agent,
        synthesizer=synthesizer_agent,
        gumbel_selector=gumbel_selector
    )
    print("[1g] âœ… Orchestrator å·²æˆåŠŸåˆå§‹åŒ–.")
    
    print("\nâœ… æ­¥éª¤ä¸€ç»“æŸï¼šæ‰€æœ‰ç»„ä»¶å·²å°±ä½.")
    print("="*30)

    # ==========================================================================
    # æ­¥éª¤ 2: æ‰¹é‡ç”Ÿæˆç»“æœ
    # ==========================================================================
    print("\næ­¥éª¤ 2: å¼€å§‹æ‰¹é‡ç”Ÿæˆç»“æœ")

    with open(CONFIG["DATASET_PATH"], "r", encoding="utf-8") as f:
        examples = json.load(f)["examples"]
    
    # --- æ–­ç‚¹ç»­è·‘é€»è¾‘ (æœ€ç»ˆç‰ˆï¼šåŒæ—¶è·³è¿‡æˆåŠŸå’Œå¤±è´¥çš„æ ·æœ¬) ---
    uids_to_skip = set()
    output_dir = os.path.dirname(CONFIG["OUTPUT_FILE"])
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    success_file_path = CONFIG["OUTPUT_FILE"]
    error_file_path = success_file_path.replace(".jsonl", "_errors.jsonl")

    # 1. è¯»å–å·²æˆåŠŸçš„UID
    success_count = 0
    if os.path.exists(success_file_path):
        with open(success_file_path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    # ä½¿ç”¨.add()çš„è¿”å›å€¼æ¥è®¡æ•°æ˜¯æ— æ•ˆçš„ï¼Œéœ€è¦å•ç‹¬è®¡æ•°
                    if json.loads(line)["uid"] not in uids_to_skip:
                        uids_to_skip.add(json.loads(line)["uid"])
                        success_count += 1
                except (json.JSONDecodeError, KeyError):
                    continue
    if success_count > 0:
        print(f"â„¹ï¸  å‘ç°æˆåŠŸæ—¥å¿—ï¼Œå°†è·³è¿‡ {success_count} ä¸ªå·²æˆåŠŸçš„æ ·æœ¬ã€‚")

    # 2. è¯»å–å·²å¤±è´¥çš„UID
    error_count = 0
    if os.path.exists(error_file_path):
        with open(error_file_path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    if json.loads(line)["uid"] not in uids_to_skip:
                        uids_to_skip.add(json.loads(line)["uid"])
                        error_count += 1
                except (json.JSONDecodeError, KeyError):
                    continue
    if error_count > 0:
        print(f"â„¹ï¸  å‘ç°é”™è¯¯æ—¥å¿—ï¼Œå°†é¢å¤–è·³è¿‡ {error_count} ä¸ªå·²çŸ¥ä¼šå‡ºé”™çš„æ ·æœ¬ã€‚")
    # --- é€»è¾‘ä¿®æ”¹ç»“æŸ ---

    # --- å¾ªç¯å¤„ç†æ‰€æœ‰æ ·æœ¬ ---
    for sample in tqdm(examples, desc="æ­£åœ¨ç”Ÿæˆç»“æœ"):
        uid = sample.get("uid")
        query = sample.get("query")
        
        # --- æ›´æ–°åˆ¤æ–­æ¡ä»¶ï¼šè·³è¿‡æ‰€æœ‰å·²å¤„ç†è¿‡çš„æ ·æœ¬ ---
        if not query or (uid and uid in uids_to_skip):
            continue

        # --- å¯¹æ¯ä¸ªæ ·æœ¬çš„å¤„ç†éƒ½åŒ…è£¹åœ¨ try...except å—ä¸­ ---
        try:
            query_embedding = get_query_embedding(query_embedder, query)
            
            # 1. ç‹¬ç«‹è·å–æ£€ç´¢ç»“æœ
            modality_index = orchestrator._choose_modality(query_embedding)
            modality_name = orchestrator.modality_map.get(modality_index, "unknown")
            retrieved_nodes = search_engine.search(
                query=query, modality=modality_name, top_k=CONFIG["TOP_K"]
            )
            
            # 2. è¿è¡ŒOrchestratorè·å–ç­”æ¡ˆ
            final_answer = orchestrator.run(
                query=query,
                query_embedding=query_embedding,
                initial_top_k=CONFIG["TOP_K"],
                # pre_retrieved_nodes=retrieved_nodes # å¦‚éœ€ä¼˜åŒ–æ€§èƒ½ï¼Œè¯·ä¿®æ”¹Orchestratorå¹¶å–æ¶ˆæ­¤è¡Œæ³¨é‡Š
            )

            # --- å‡†å¤‡è¦ä¿å­˜çš„æ•°æ® ---
            result_data = {
                "uid": uid,
                "query": query,
                "reference_answer": sample.get("reference_answer"),
                "meta_info": sample.get("meta_info"),
                "generated_answer": final_answer,
                "retrieved_nodes": [node.to_dict() for node in retrieved_nodes]
            }

            # --- å°†æˆåŠŸçš„ç»“æœå®æ—¶å†™å…¥æ–‡ä»¶ ---
            with open(CONFIG["OUTPUT_FILE"], "a", encoding="utf-8") as f:
                f.write(json.dumps(result_data, ensure_ascii=False) + "\n")

        except Exception as e:
            # --- å¦‚æœå‘ç”Ÿå¼‚å¸¸ï¼Œè®°å½•é”™è¯¯å¹¶ç»§ç»­ ---
            print(f"\nâŒ å¤„ç†æ ·æœ¬ {uid} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            error_details = {
                "uid": uid,
                "query": query,
                "error_message": str(e),
                "traceback": traceback.format_exc()
            }
            # å†™å…¥ç‹¬ç«‹çš„é”™è¯¯æ—¥å¿—æ–‡ä»¶
            with open(error_file_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(error_details, ensure_ascii=False) + "\n")
            continue # ç»§ç»­ä¸‹ä¸€ä¸ªæ ·æœ¬
    
    print("\nğŸ‰ æ‰€æœ‰æ ·æœ¬ç”Ÿæˆå®Œæ¯•ï¼")
    print(f"âœ… æˆåŠŸç»“æœå·²ä¿å­˜è‡³: {CONFIG['OUTPUT_FILE']}")
    if os.path.exists(error_file_path):
        print(f"âš ï¸  éƒ¨åˆ†æ ·æœ¬å¤„ç†å¤±è´¥ï¼Œé”™è¯¯è¯¦æƒ…å·²è®°å½•åœ¨: {error_file_path}")

if __name__ == '__main__':
    main()